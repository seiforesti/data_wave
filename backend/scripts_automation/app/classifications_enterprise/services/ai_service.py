import logging
import asyncio
import json
import aiohttp
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, desc
import uuid
import numpy as np
from pathlib import Path

# AI and LLM Libraries
try:
    import openai
    from transformers import AutoTokenizer, AutoModel, pipeline, GPT2TokenizerFast
    import torch
    from sentence_transformers import SentenceTransformer
except ImportError:
    logging.warning("AI libraries not available, AI features will be limited")

try:
    import networkx as nx
    from sklearn.metrics.pairwise import cosine_similarity
    import spacy
except ImportError:
    logging.warning("Advanced NLP libraries not available")

from ..models.ai_models import (
    AIModel, IntelligentAssistantSession, AssistantInteraction, AIInsight,
    DomainIntelligence, ContextAwareSearch, AutoGeneratedTag, 
    AIOptimizationRecommendation, ExplainableAITrace,
    AIModelType, IntelligenceLevel, InsightType, RecommendationPriority
)
from ..models.classification_models import ClassificationResult, SensitivityLabelEnum

logger = logging.getLogger(__name__)

class AIIntelligentClassificationService:
    """Advanced AI service for enterprise-grade intelligent classification"""
    
    def __init__(self, ai_config: Dict[str, Any] = None):
        self.ai_config = ai_config or {}
        self.llm_client = None
        self.embedding_model = None
        self.graph_knowledge = nx.Graph()
        self.domain_experts = {}
        self.active_sessions = {}
        
        # Initialize AI models
        asyncio.create_task(self._initialize_ai_models())
    
    async def _initialize_ai_models(self):
        """Initialize AI models and clients"""
        try:
            # Initialize LLM client (OpenAI, Azure OpenAI, or local models)
            if self.ai_config.get('openai_api_key'):
                openai.api_key = self.ai_config['openai_api_key']
                self.llm_client = openai
            
            # Initialize embedding model for semantic understanding
            if 'sentence_transformers' in globals():
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            
            logger.info("AI models initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing AI models: {str(e)}")
    
    async def create_ai_model(self, session: Session, model_config: Dict[str, Any], user: str) -> AIModel:
        """Create a new AI model configuration"""
        try:
            ai_model = AIModel(
                uuid=uuid.uuid4(),
                name=model_config['name'],
                description=model_config.get('description', ''),
                model_type=AIModelType(model_config['model_type']),
                architecture_details=model_config.get('architecture_details', {}),
                parameter_count=model_config.get('parameter_count', 0),
                context_window_size=model_config.get('context_window_size', 4096),
                capabilities=model_config.get('capabilities', []),
                intelligence_level=IntelligenceLevel(model_config.get('intelligence_level', 'advanced')),
                specialized_domains=model_config.get('specialized_domains', []),
                api_endpoint=model_config.get('api_endpoint', ''),
                cost_per_request=model_config.get('cost_per_request', 0.0),
                created_by=user
            )
            
            session.add(ai_model)
            session.commit()
            session.refresh(ai_model)
            
            logger.info(f"Created AI model: {ai_model.name} (ID: {ai_model.id})")
            return ai_model
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error creating AI model: {str(e)}")
            raise
    
    async def start_intelligent_session(self, session: Session, ai_model_id: int, user_id: str, context: Dict[str, Any]) -> IntelligentAssistantSession:
        """Start an intelligent assistant session"""
        try:
            ai_model = session.get(AIModel, ai_model_id)
            if not ai_model:
                raise ValueError(f"AI model {ai_model_id} not found")
            
            assistant_session = IntelligentAssistantSession(
                uuid=uuid.uuid4(),
                ai_model_id=ai_model_id,
                user_id=user_id,
                session_name=f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                domain_context=context.get('domain_context', {}),
                entity_context=context.get('entity_context', {}),
                user_preferences=context.get('user_preferences', {}),
                last_interaction_at=datetime.utcnow()
            )
            
            session.add(assistant_session)
            session.commit()
            session.refresh(assistant_session)
            
            # Cache session for real-time interactions
            self.active_sessions[assistant_session.uuid] = {
                'session': assistant_session,
                'conversation_history': [],
                'context_memory': context
            }
            
            logger.info(f"Started intelligent assistant session: {assistant_session.uuid}")
            return assistant_session
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error starting assistant session: {str(e)}")
            raise
    
    async def process_intelligent_query(self, session: Session, session_id: str, user_input: str, context: Dict[str, Any] = None) -> AssistantInteraction:
        """Process an intelligent query with advanced AI reasoning"""
        try:
            session_data = self.active_sessions.get(session_id)
            if not session_data:
                raise ValueError(f"Session {session_id} not found or expired")
            
            assistant_session = session_data['session']
            ai_model = session.get(AIModel, assistant_session.ai_model_id)
            
            start_time = datetime.utcnow()
            
            # Analyze user intent and extract entities
            intent_analysis = await self._analyze_user_intent(user_input, context or {})
            
            # Generate intelligent response using advanced AI
            response_data = await self._generate_intelligent_response(
                user_input, 
                intent_analysis, 
                session_data['conversation_history'],
                session_data['context_memory'],
                ai_model
            )
            
            end_time = datetime.utcnow()
            response_time = (end_time - start_time).total_seconds() * 1000
            
            # Create interaction record
            interaction = AssistantInteraction(
                session_id=assistant_session.id,
                user_input=user_input,
                assistant_response=response_data['response'],
                interaction_type=intent_analysis.get('interaction_type', 'question'),
                detected_intent=intent_analysis.get('intent', 'unknown'),
                entities_extracted=intent_analysis.get('entities', {}),
                confidence_score=intent_analysis.get('confidence', 0.8),
                reasoning_chain=response_data.get('reasoning_chain', []),
                sources_cited=response_data.get('sources_cited', []),
                uncertainty_indicators=response_data.get('uncertainty_indicators', {}),
                response_time_ms=response_time,
                tokens_used=response_data.get('tokens_used', 0),
                cost_incurred=response_data.get('cost_incurred', 0.0)
            )
            
            session.add(interaction)
            
            # Update session statistics
            assistant_session.total_interactions += 1
            assistant_session.last_interaction_at = datetime.utcnow()
            
            session.commit()
            session.refresh(interaction)
            
            # Update conversation history
            session_data['conversation_history'].append({
                'user': user_input,
                'assistant': response_data['response'],
                'timestamp': datetime.utcnow().isoformat(),
                'intent': intent_analysis.get('intent'),
                'entities': intent_analysis.get('entities', {})
            })
            
            logger.info(f"Processed intelligent query in session {session_id}")
            return interaction
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error processing intelligent query: {str(e)}")
            raise
    
    async def generate_ai_insights(self, session: Session, ai_model_id: int, entity_type: str, entity_id: str, entity_data: Dict[str, Any], user: str) -> List[AIInsight]:
        """Generate AI-powered insights for data entities"""
        try:
            ai_model = session.get(AIModel, ai_model_id)
            if not ai_model:
                raise ValueError(f"AI model {ai_model_id} not found")
            
            insights = []
            
            # Generate different types of insights
            insight_generators = [
                self._generate_data_quality_insights,
                self._generate_business_value_insights,
                self._generate_risk_assessment_insights,
                self._generate_optimization_insights,
                self._generate_relationship_insights
            ]
            
            for generator in insight_generators:
                try:
                    generated_insights = await generator(entity_type, entity_id, entity_data, ai_model)
                    for insight_data in generated_insights:
                        insight = AIInsight(
                            uuid=uuid.uuid4(),
                            ai_model_id=ai_model_id,
                            title=insight_data['title'],
                            description=insight_data['description'],
                            insight_type=InsightType(insight_data['insight_type']),
                            priority=RecommendationPriority(insight_data['priority']),
                            entity_type=entity_type,
                            entity_id=entity_id,
                            entity_metadata=entity_data,
                            key_findings=insight_data.get('key_findings', {}),
                            recommendations=insight_data.get('recommendations', {}),
                            risk_assessment=insight_data.get('risk_assessment', {}),
                            business_impact=insight_data.get('business_impact', {}),
                            evidence_sources=insight_data.get('evidence_sources', []),
                            confidence_score=insight_data.get('confidence_score', 0.8),
                            reasoning_explanation=insight_data.get('reasoning_explanation', ''),
                            action_items=insight_data.get('action_items', []),
                            estimated_effort=insight_data.get('estimated_effort', 'medium'),
                            expected_outcome=insight_data.get('expected_outcome', ''),
                            success_metrics=insight_data.get('success_metrics', {}),
                            urgency_level=insight_data.get('urgency_level', 'medium'),
                            generated_by=user
                        )
                        
                        session.add(insight)
                        insights.append(insight)
                        
                except Exception as e:
                    logger.warning(f"Error generating insights with {generator.__name__}: {str(e)}")
                    continue
            
            session.commit()
            
            for insight in insights:
                session.refresh(insight)
            
            logger.info(f"Generated {len(insights)} AI insights for {entity_type}:{entity_id}")
            return insights
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error generating AI insights: {str(e)}")
            raise
    
    async def perform_context_aware_search(self, session: Session, query: str, user_id: str, context: Dict[str, Any]) -> ContextAwareSearch:
        """Perform context-aware intelligent search"""
        try:
            start_time = datetime.utcnow()
            
            # Analyze query and user context
            query_analysis = await self._analyze_search_query(query, context)
            
            # Expand query using semantic understanding
            expanded_query = await self._expand_search_query(query, query_analysis, context)
            
            # Perform semantic search with context enrichment
            search_results = await self._perform_semantic_search(expanded_query, context)
            
            # Apply personalization based on user context
            personalized_results = await self._personalize_search_results(search_results, user_id, context)
            
            end_time = datetime.utcnow()
            search_time = (end_time - start_time).total_seconds() * 1000
            
            # Create search record
            context_search = ContextAwareSearch(
                uuid=uuid.uuid4(),
                query_text=query,
                user_id=user_id,
                search_intent=query_analysis.get('intent', 'unknown'),
                user_context=context.get('user_context', {}),
                entity_context=context.get('entity_context', {}),
                temporal_context=context.get('temporal_context', {}),
                domain_context=context.get('domain_context', {}),
                query_expansion=expanded_query,
                semantic_understanding=query_analysis,
                context_enrichment=context.get('enrichment_applied', {}),
                results=personalized_results,
                result_count=len(personalized_results),
                personalization_applied=context.get('personalization_applied', {}),
                search_time_ms=search_time,
                relevance_score=np.mean([r.get('relevance_score', 0.5) for r in personalized_results])
            )
            
            session.add(context_search)
            session.commit()
            session.refresh(context_search)
            
            logger.info(f"Performed context-aware search: '{query}' -> {len(personalized_results)} results")
            return context_search
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error performing context-aware search: {str(e)}")
            raise
    
    async def auto_generate_tags(self, session: Session, entity_type: str, entity_id: str, entity_data: Dict[str, Any], user: str) -> List[AutoGeneratedTag]:
        """Auto-generate intelligent tags using AI"""
        try:
            tags = []
            
            # Use different AI methods for tag generation
            tag_generators = [
                self._generate_llm_tags,
                self._generate_pattern_based_tags,
                self._generate_graph_analysis_tags,
                self._generate_semantic_tags
            ]
            
            for generator in tag_generators:
                try:
                    generated_tags = await generator(entity_type, entity_id, entity_data)
                    
                    for tag_data in generated_tags:
                        tag = AutoGeneratedTag(
                            entity_type=entity_type,
                            entity_id=entity_id,
                            tag_name=tag_data['tag_name'],
                            tag_value=tag_data.get('tag_value', ''),
                            tag_category=tag_data.get('tag_category', 'general'),
                            generation_method=tag_data['generation_method'],
                            confidence_score=tag_data['confidence_score'],
                            reasoning=tag_data.get('reasoning', ''),
                            generated_by=user
                        )
                        
                        session.add(tag)
                        tags.append(tag)
                        
                except Exception as e:
                    logger.warning(f"Error generating tags with {generator.__name__}: {str(e)}")
                    continue
            
            session.commit()
            
            for tag in tags:
                session.refresh(tag)
            
            logger.info(f"Auto-generated {len(tags)} tags for {entity_type}:{entity_id}")
            return tags
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error auto-generating tags: {str(e)}")
            raise
    
    async def create_optimization_recommendation(self, session: Session, target_system: str, analysis_data: Dict[str, Any], user: str) -> AIOptimizationRecommendation:
        """Create AI-powered optimization recommendations"""
        try:
            # Analyze current state and identify optimization opportunities
            optimization_analysis = await self._analyze_optimization_opportunities(target_system, analysis_data)
            
            recommendation = AIOptimizationRecommendation(
                uuid=uuid.uuid4(),
                target_system=target_system,
                target_component=analysis_data.get('target_component', ''),
                optimization_type=optimization_analysis['optimization_type'],
                current_state=analysis_data.get('current_state', {}),
                recommended_changes=optimization_analysis['recommended_changes'],
                expected_improvements=optimization_analysis['expected_improvements'],
                implementation_steps=optimization_analysis['implementation_steps'],
                estimated_effort_hours=optimization_analysis.get('estimated_effort_hours', 0.0),
                required_resources=optimization_analysis.get('required_resources', {}),
                risk_assessment=optimization_analysis.get('risk_assessment', {}),
                cost_savings_annual=optimization_analysis.get('cost_savings_annual', 0.0),
                performance_improvement_percentage=optimization_analysis.get('performance_improvement_percentage', 0.0),
                roi_months=optimization_analysis.get('roi_months', 12.0),
                created_by=user
            )
            
            session.add(recommendation)
            session.commit()
            session.refresh(recommendation)
            
            logger.info(f"Created optimization recommendation for {target_system}")
            return recommendation
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error creating optimization recommendation: {str(e)}")
            raise
    
    async def create_explainable_trace(self, session: Session, decision_id: str, model_used: str, decision_data: Dict[str, Any], user: str) -> ExplainableAITrace:
        """Create explainable AI trace for transparency"""
        try:
            # Generate comprehensive explanation
            explanation = await self._generate_explainable_trace(decision_data, model_used)
            
            trace = ExplainableAITrace(
                decision_id=decision_id,
                model_used=model_used,
                input_data=decision_data.get('input_data', {}),
                feature_importance=explanation.get('feature_importance', {}),
                attention_weights=explanation.get('attention_weights', {}),
                reasoning_steps=explanation.get('reasoning_steps', []),
                alternative_paths_considered=explanation.get('alternative_paths_considered', []),
                confidence_intervals=explanation.get('confidence_intervals', {}),
                decision_rationale=explanation['decision_rationale'],
                key_factors=explanation.get('key_factors', []),
                uncertainty_sources=explanation.get('uncertainty_sources', []),
                decision_maker=model_used
            )
            
            session.add(trace)
            session.commit()
            session.refresh(trace)
            
            logger.info(f"Created explainable AI trace for decision {decision_id}")
            return trace
            
        except Exception as e:
            session.rollback()
            logger.error(f"Error creating explainable trace: {str(e)}")
            raise
    
    # Private helper methods for AI processing
    
    async def _analyze_user_intent(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze user intent using NLP and context"""
        try:
            # Use LLM for intent analysis if available
            if self.llm_client:
                prompt = f"""
                Analyze the following user input and determine the intent, entities, and interaction type.
                
                User Input: "{user_input}"
                Context: {json.dumps(context, indent=2)}
                
                Provide analysis in JSON format with fields: intent, entities, interaction_type, confidence.
                """
                
                response = await self._call_llm(prompt)
                return json.loads(response)
            
            # Fallback to simple intent analysis
            return {
                'intent': 'classification_query',
                'entities': {},
                'interaction_type': 'question',
                'confidence': 0.7
            }
            
        except Exception as e:
            logger.error(f"Error analyzing user intent: {str(e)}")
            return {'intent': 'unknown', 'entities': {}, 'interaction_type': 'question', 'confidence': 0.5}
    
    async def _generate_intelligent_response(self, user_input: str, intent_analysis: Dict[str, Any], conversation_history: List[Dict], context_memory: Dict[str, Any], ai_model: AIModel) -> Dict[str, Any]:
        """Generate intelligent response using advanced AI"""
        try:
            # Build comprehensive prompt with context
            prompt = self._build_intelligent_prompt(user_input, intent_analysis, conversation_history, context_memory)
            
            # Generate response using LLM
            response = await self._call_llm(prompt, ai_model)
            
            return {
                'response': response,
                'reasoning_chain': [],  # Would be populated by actual reasoning
                'sources_cited': [],
                'uncertainty_indicators': {},
                'tokens_used': len(response.split()) * 1.3,  # Approximate
                'cost_incurred': 0.001  # Approximate
            }
            
        except Exception as e:
            logger.error(f"Error generating intelligent response: {str(e)}")
            return {
                'response': "I apologize, but I'm having trouble processing your request right now. Please try again.",
                'reasoning_chain': [],
                'sources_cited': [],
                'uncertainty_indicators': {'error': str(e)},
                'tokens_used': 0,
                'cost_incurred': 0.0
            }
    
    async def _call_llm(self, prompt: str, ai_model: AIModel = None) -> str:
        """Call LLM API with prompt"""
        try:
            if self.llm_client and hasattr(self.llm_client, 'Completion'):
                response = await self.llm_client.Completion.acreate(
                    engine="text-davinci-003",
                    prompt=prompt,
                    max_tokens=500,
                    temperature=0.7
                )
                return response.choices[0].text.strip()
            
            # Fallback response
            return "This is a simulated AI response. In production, this would be powered by a real LLM."
            
        except Exception as e:
            logger.error(f"Error calling LLM: {str(e)}")
            return "I'm sorry, I'm unable to provide a response at this time."
    
    def _build_intelligent_prompt(self, user_input: str, intent_analysis: Dict[str, Any], conversation_history: List[Dict], context_memory: Dict[str, Any]) -> str:
        """Build comprehensive prompt for intelligent response generation"""
        return f"""
        You are an advanced AI assistant specializing in data classification and governance.
        
        User Input: {user_input}
        Intent: {intent_analysis.get('intent', 'unknown')}
        Entities: {intent_analysis.get('entities', {})}
        
        Context:
        - Domain: {context_memory.get('domain_context', {})}
        - Current Entities: {context_memory.get('entity_context', {})}
        
        Recent Conversation:
        {json.dumps(conversation_history[-3:], indent=2) if conversation_history else 'No previous conversation'}
        
        Provide a helpful, accurate, and contextually relevant response.
        """
    
    # Insight generation methods
    
    async def _generate_data_quality_insights(self, entity_type: str, entity_id: str, entity_data: Dict[str, Any], ai_model: AIModel) -> List[Dict[str, Any]]:
        """Generate data quality insights"""
        insights = []
        
        # Analyze data completeness, consistency, accuracy, etc.
        if 'data_profile' in entity_data:
            profile = entity_data['data_profile']
            
            # Completeness insight
            if profile.get('null_percentage', 0) > 10:
                insights.append({
                    'title': 'Data Completeness Issue Detected',
                    'description': f'High percentage of null values ({profile["null_percentage"]:.1f}%) detected in {entity_type}',
                    'insight_type': 'data_quality',
                    'priority': 'high',
                    'key_findings': {'null_percentage': profile['null_percentage']},
                    'recommendations': ['Implement data validation rules', 'Review data collection processes'],
                    'confidence_score': 0.9
                })
        
        return insights
    
    async def _generate_business_value_insights(self, entity_type: str, entity_id: str, entity_data: Dict[str, Any], ai_model: AIModel) -> List[Dict[str, Any]]:
        """Generate business value insights"""
        return [{
            'title': 'High Business Value Data Asset',
            'description': f'This {entity_type} contains high-value data for business analytics',
            'insight_type': 'business_value',
            'priority': 'medium',
            'business_impact': {'value_score': 0.8},
            'confidence_score': 0.7
        }]
    
    async def _generate_risk_assessment_insights(self, entity_type: str, entity_id: str, entity_data: Dict[str, Any], ai_model: AIModel) -> List[Dict[str, Any]]:
        """Generate risk assessment insights"""
        return []  # Implementation would analyze security, compliance, and operational risks
    
    async def _generate_optimization_insights(self, entity_type: str, entity_id: str, entity_data: Dict[str, Any], ai_model: AIModel) -> List[Dict[str, Any]]:
        """Generate optimization insights"""
        return []  # Implementation would identify performance and cost optimization opportunities
    
    async def _generate_relationship_insights(self, entity_type: str, entity_id: str, entity_data: Dict[str, Any], ai_model: AIModel) -> List[Dict[str, Any]]:
        """Generate relationship and lineage insights"""
        return []  # Implementation would discover hidden relationships between data entities
    
    # Additional helper methods would be implemented here for:
    # - Search query analysis and expansion
    # - Semantic search implementation
    # - Tag generation methods
    # - Optimization analysis
    # - Explainable AI trace generation